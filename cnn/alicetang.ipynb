{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! cp /content/drive/MyDrive/Stat_Docs/kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change permission\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset Download\n",
    "Link to dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle datasets download -d awsaf49/cbis-ddsm-breast-cancer-image-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check disk usage\n",
    "! df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random \n",
    "import tensorflow as tf\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_train = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/calc_case_description_train_set.csv')\n",
    "calc_test = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/calc_case_description_test_set.csv')\n",
    "mass_train = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/mass_case_description_train_set.csv')\n",
    "mass_test = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/mass_case_description_test_set.csv')\n",
    "dicom_data = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/dicom_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the directory in the dicom_info.csv in order to load the imgs correctly\n",
    "image_dir = '/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/jpeg/'\n",
    "full_mammogram_images = dicom_data[dicom_data.SeriesDescription == 'full mammogram images'].image_path\n",
    "cropped_images = dicom_data[dicom_data.SeriesDescription == 'cropped images'].image_path\n",
    "roi_mask_images = dicom_data[dicom_data.SeriesDescription == 'ROI mask images'].image_path\n",
    "\n",
    "full_mammogram_images = full_mammogram_images.apply(lambda x: x.replace('CBIS-DDSM/jpeg', image_dir))\n",
    "cropped_images = cropped_images.apply(lambda x: x.replace('CBIS-DDSM/jpeg', image_dir))\n",
    "roi_mask_images = roi_mask_images.apply(lambda x: x.replace('CBIS-DDSM/jpeg', image_dir))\n",
    "full_mammogram_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_cleaning_data = dicom_data.copy()\n",
    "dicom_cleaning_data['image_path'] = dicom_cleaning_data['image_path'].str.replace('CBIS-DDSM/jpeg/', image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_cleaning_data.drop(['PatientBirthDate','AccessionNumber','Columns','ContentDate','ContentTime','PatientSex','PatientBirthDate',\n",
    "                                                'ReferringPhysicianName','Rows','SOPClassUID','SOPInstanceUID',\n",
    "                                                'StudyDate','StudyID','StudyInstanceUID','StudyTime','InstanceNumber','SeriesInstanceUID','SeriesNumber'],axis =1, inplace=True)\n",
    "dicom_cleaning_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_cleaning_data['SeriesDescription'].fillna(0, axis = 0, inplace=True)\n",
    "dicom_cleaning_data['Laterality'].fillna(method = 'bfill', axis = 0, inplace=True)\n",
    "\n",
    "dicom_cleaning_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the labels\n",
    "label_mapping = {'BENIGN': 0, 'MALIGNANT': 1, 'BENIGN_WITHOUT_CALLBACK': 2}\n",
    "calc_train['label'] = calc_train['pathology'].map(label_mapping)\n",
    "calc_test['label'] = calc_test['pathology'].map(label_mapping)\n",
    "mass_train['label'] = mass_train['pathology'].map(label_mapping)\n",
    "mass_test['label'] = mass_test['pathology'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our functions to load and process mammograms, focusing on all 3 types of images (full mammogram, cropped images, ROI mask)\n",
    "\n",
    "dicom_model = dicom_data.copy()\n",
    "dicom_model['image_path'] = dicom_cleaning_data['image_path'].str.replace('CBIS-DDSM/jpeg/', image_dir)\n",
    "\n",
    "# image loading and processing fxn to numpy array\n",
    "def load_and_process_image(image_path):\n",
    "    image = load_img(image_path, target_size=(224,224), color_mode=\"grayscale\")\n",
    "    image = img_to_array(image) / 255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "def match1(file_path):\n",
    "    patientID = file_path.split('/')[0]\n",
    "    series_description = 'full mammogram images'\n",
    "    filtered_df = dicom_cleaning_data[(dicom_cleaning_data['SeriesDescription'] == series_description) & \n",
    "                            (dicom_cleaning_data['PatientName'] == patientID)]\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        return None\n",
    "    #print(1)\n",
    "    return filtered_df['image_path'].iloc[0]\n",
    "\n",
    "def match2(file_path):\n",
    "    patientID = file_path.split('/')[0]\n",
    "    series_description = 'cropped images'\n",
    "    filtered_df = dicom_cleaning_data[(dicom_cleaning_data['SeriesDescription'] == series_description) & \n",
    "                            (dicom_cleaning_data['PatientName'] == patientID)]\n",
    "    if filtered_df.empty:\n",
    "        return None\n",
    "    #print(2)\n",
    "    return filtered_df['image_path'].iloc[0]\n",
    "\n",
    "def match3(file_path):\n",
    "    patientID = file_path.split('/')[0]\n",
    "    series_description = 'ROI mask images'\n",
    "\n",
    "    filtered_df = dicom_cleaning_data[(dicom_cleaning_data['SeriesDescription'] == series_description) & \n",
    "                            (dicom_cleaning_data['PatientName'] == patientID)]\n",
    "    if filtered_df.empty:\n",
    "        print('no')\n",
    "        return None\n",
    "    #print(3)\n",
    "    return filtered_df['image_path'].iloc[0]\n",
    "\n",
    "# data loading \n",
    "def load_data(df):\n",
    "    full_imgs = []\n",
    "    cropped_imgs = []\n",
    "    roi_imgs = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        full_img_path = match1(row['image file path'])\n",
    "        if full_img_path is None:\n",
    "            continue\n",
    "        cropped_img_path = match2(row['cropped image file path'])\n",
    "        if cropped_img_path is None:\n",
    "            continue\n",
    "        roi_img_path = match3(row['ROI mask file path'])\n",
    "        if roi_img_path is None:\n",
    "            continue\n",
    "        # roi_img_path = match4(row['ROI mask file path'])\n",
    "        # if roi_img_path is None:\n",
    "        #     continue\n",
    "\n",
    "        if full_img_path is not None and cropped_img_path is not None and roi_img_path is not None:\n",
    "            if os.path.exists(full_img_path) and os.path.exists(cropped_img_path) and os.path.exists(roi_img_path):\n",
    "                full_imgs.append(load_and_process_image(full_img_path))\n",
    "                cropped_imgs.append(load_and_process_image(cropped_img_path))\n",
    "                roi_imgs.append(load_and_process_image(roi_img_path))\n",
    "                labels.append(row['label'])\n",
    "            \n",
    "\n",
    "    return np.array(full_imgs), np.array(cropped_imgs), np.array(roi_imgs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, for calc_train - identify and remove duplicate image file paths.\n",
    "calc_train['image file path'].nunique()\n",
    "calc_train_model = calc_train.copy()\n",
    "calc_train_model = calc_train_model.drop_duplicates(subset=['image file path']).reset_index(drop=True)\n",
    "calc_train_model['image file path'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass_train.\n",
    "print(mass_train['image file path'].nunique())\n",
    "mass_train_model = mass_train.copy()\n",
    "mass_train_model = mass_train_model.drop_duplicates(subset=['image file path']).reset_index(drop=True)\n",
    "mass_train_model['image file path'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass_test.\n",
    "print(mass_test['image file path'].nunique())\n",
    "mass_test_model = mass_test.copy()\n",
    "mass_test_model = mass_test_model.drop_duplicates(subset=['image file path']).reset_index(drop=True)\n",
    "mass_test_model['image file path'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_test.\n",
    "print(calc_test['image file path'].nunique())\n",
    "calc_test_model = calc_test.copy()\n",
    "calc_test_model = calc_test_model.drop_duplicates(subset=['image file path']).reset_index(drop=True)\n",
    "calc_test_model['image file path'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data-frame\n",
    "calc_train_model.info()\n",
    "print(\"/n\")\n",
    "mass_train_model.info()\n",
    "print(\"/n\")\n",
    "calc_test_model.info()\n",
    "print(\"/n\")\n",
    "mass_test_model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(match1(calc_train_model['image file path'][1000]))\n",
    "print(match2(calc_train_model['cropped image file path'][1000]))\n",
    "print(match3(calc_train_model['ROI mask file path'][1000]))\n",
    "calc_train_model['label'][1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_calc_full_train, x_calc_cropped_train, x_calc_roi_train, y_calc_train = [],[],[],[]\n",
    "x_calc_full_train, x_calc_cropped_train, x_calc_roi_train, y_calc_train = load_data(calc_train_model)\n",
    "\n",
    "x_calc_full_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_calc_full_test = x_calc_full_train[1000:]\n",
    "x_calc_cropped_test = x_calc_cropped_train[1000:]\n",
    "x_calc_roi_test = x_calc_roi_train[1000:]\n",
    "y_calc_test = y_calc_train[1000:]\n",
    "\n",
    "x_calc_full_train = x_calc_full_train[:1000]\n",
    "x_calc_cropped_train = x_calc_cropped_train[:1000]\n",
    "x_calc_roi_train = x_calc_roi_train[:1000]\n",
    "y_calc_train = y_calc_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_calc_roi_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mass_full_train, x_mass_cropped_train, x_mass_roi_train, y_mass_train = [],[],[],[]\n",
    "x_mass_full_train, x_mass_cropped_train, x_mass_roi_train, y_mass_train = load_data(mass_train_model)\n",
    "x_mass_cropped_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mass_full_test, x_mass_cropped_test, x_mass_roi_test, y_mass_test = [], [], [], []\n",
    "x_mass_full_test, x_mass_cropped_test, x_mass_roi_test, y_mass_test = load_data(mass_test_model)\n",
    "x_mass_cropped_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the training data \n",
    "x_full = np.concatenate([x_calc_full_train,x_mass_full_train], axis=0)\n",
    "x_cropped = np.concatenate([x_calc_cropped_train,x_mass_cropped_train], axis=0)\n",
    "x_roi = np.concatenate([x_calc_roi_train,x_mass_roi_train], axis=0)\n",
    "y = np.concatenate([y_calc_train,y_mass_train], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine testing data \n",
    "x_full_test = np.concatenate([x_calc_full_test,x_mass_full_test], axis=0)\n",
    "x_cropped_test = np.concatenate([x_calc_cropped_test,x_mass_cropped_test], axis=0)\n",
    "x_roi_test = np.concatenate([x_calc_roi_test,x_mass_roi_test], axis=0)\n",
    "y_test = np.concatenate([y_calc_test,y_mass_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape of np arrays above\n",
    "print(f\"x_full shape: {x_full.shape}, /n x_cropped shape: {x_cropped.shape}, /n x_roi shape: {x_roi.shape}, /n y shape: {y.shape}\")\n",
    "print(f\"x_full_test shape: {x_full_test.shape}, /n x_cropped_test shape: {x_cropped_test.shape}, /n x_roi_test shape: {x_roi_test.shape}, /n y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to categorical\n",
    "from tensoflow.keras.utils import to_categorical\n",
    "y = to_categorical(y, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multi_input_model(input_shape = (224, 224, 3)):\n",
    "    full_input = Input(shape=input_shape, name='full_input')\n",
    "    x1 = Conv2D(32, (3, 3), activation='relu', padding='same')(full_input)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Dropout(0.25)(x1)\n",
    "    \n",
    "    cropped_input = Input(shape=input_shape, name='cropped_input')\n",
    "    x2 = Conv2D(32, (3, 3), activation='relu', padding='same')(cropped_input)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    x2 = Dropout(0.25)(x2)\n",
    "    \n",
    "    roi_input = Input(shape=input_shape, name='roi_input')\n",
    "    x3 = Conv2D(32, (3, 3), activation='relu', padding='same')(roi_input)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "    x3 = Dropout(0.25)(x3)\n",
    "    \n",
    "    merged = concatenate([x1, x2, x3])\n",
    "\n",
    "    # fully connected layers\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(merged)  # Add L2 regularization\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    output = Dense(3, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[full_input, cropped_input, roi_input], outputs=output)\n",
    "\n",
    "    # Compile model with Adam optimizer and custom learning rate\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
