{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! cp /content/drive/MyDrive/Stat_Docs/kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change permission\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset Download\n",
    "Link to dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle datasets download -d awsaf49/cbis-ddsm-breast-cancer-image-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check disk usage\n",
    "! df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random \n",
    "import tensorflow as tf\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_train = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/calc_case_description_train_set.csv')\n",
    "calc_test = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/calc_case_description_test_set.csv')\n",
    "mass_train = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/mass_case_description_train_set.csv')\n",
    "mass_test = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/mass_case_description_test_set.csv')\n",
    "dicom_data = pd.read_csv('/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/csv/dicom_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the directory in the dicom_info.csv in order to load the imgs correctly\n",
    "image_dir = '/kaggle/input/cbis-ddsm-breast-cancer-image-dataset/jpeg/'\n",
    "full_mammogram_images = dicom_data[dicom_data.SeriesDescription == 'full mammogram images'].image_path\n",
    "cropped_images = dicom_data[dicom_data.SeriesDescription == 'cropped images'].image_path\n",
    "roi_mask_images = dicom_data[dicom_data.SeriesDescription == 'ROI mask images'].image_path\n",
    "\n",
    "full_mammogram_images = full_mammogram_images.apply(lambda x: x.replace('CBIS-DDSM/jpeg', image_dir))\n",
    "cropped_images = cropped_images.apply(lambda x: x.replace('CBIS-DDSM/jpeg', image_dir))\n",
    "roi_mask_images = roi_mask_images.apply(lambda x: x.replace('CBIS-DDSM/jpeg', image_dir))\n",
    "full_mammogram_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_cleaning_data = dicom_data.copy()\n",
    "dicom_cleaning_data['image_path'] = dicom_cleaning_data['image_path'].str.replace('CBIS-DDSM/jpeg/', image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_cleaning_data.drop(['PatientBirthDate','AccessionNumber','Columns','ContentDate','ContentTime','PatientSex','PatientBirthDate',\n",
    "                                                'ReferringPhysicianName','Rows','SOPClassUID','SOPInstanceUID',\n",
    "                                                'StudyDate','StudyID','StudyInstanceUID','StudyTime','InstanceNumber','SeriesInstanceUID','SeriesNumber'],axis =1, inplace=True)\n",
    "dicom_cleaning_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_cleaning_data['SeriesDescription'].fillna(0, axis = 0, inplace=True)\n",
    "dicom_cleaning_data['Laterality'].fillna(method = 'bfill', axis = 0, inplace=True)\n",
    "\n",
    "dicom_cleaning_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the labels\n",
    "label_mapping = {'BENIGN': 0, 'MALIGNANT': 1, 'BENIGN_WITHOUT_CALLBACK': 2}\n",
    "calc_train['label'] = calc_train['pathology'].map(label_mapping)\n",
    "calc_test['label'] = calc_test['pathology'].map(label_mapping)\n",
    "mass_train['label'] = mass_train['pathology'].map(label_mapping)\n",
    "mass_test['label'] = mass_test['pathology'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our functions to load and process mammograms, focusing on all 3 types of images (full mammogram, cropped images, ROI mask)\n",
    "\n",
    "dicom_model = dicom_data.copy()\n",
    "dicom_model['image_path'] = dicom_cleaning_data['image_path'].str.replace('CBIS-DDSM/jpeg/', image_dir)\n",
    "\n",
    "# image loading and processing fxn to numpy array\n",
    "def load_and_process_image(image_path):\n",
    "    image = load_img(image_path, target_size=(224,224), color_mode=\"grayscale\")\n",
    "    image = img_to_array(image) / 255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "def match1(file_path):\n",
    "    patientID = file_path.split('/')[0]\n",
    "    series_description = 'full mammogram images'\n",
    "    filtered_df = dicom_cleaning_data[(dicom_cleaning_data['SeriesDescription'] == series_description) & \n",
    "                            (dicom_cleaning_data['PatientName'] == patientID)]\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        return None\n",
    "    #print(1)\n",
    "    return filtered_df['image_path'].iloc[0]\n",
    "\n",
    "def match2(file_path):\n",
    "    patientID = file_path.split('/')[0]\n",
    "    series_description = 'cropped images'\n",
    "    filtered_df = dicom_cleaning_data[(dicom_cleaning_data['SeriesDescription'] == series_description) & \n",
    "                            (dicom_cleaning_data['PatientName'] == patientID)]\n",
    "    if filtered_df.empty:\n",
    "        return None\n",
    "    #print(2)\n",
    "    return filtered_df['image_path'].iloc[0]\n",
    "\n",
    "def match3(file_path):\n",
    "    patientID = file_path.split('/')[0]\n",
    "    series_description = 'ROI mask images'\n",
    "\n",
    "    filtered_df = dicom_cleaning_data[(dicom_cleaning_data['SeriesDescription'] == series_description) & \n",
    "                            (dicom_cleaning_data['PatientName'] == patientID)]\n",
    "    if filtered_df.empty:\n",
    "        print('no')\n",
    "        return None\n",
    "    #print(3)\n",
    "    return filtered_df['image_path'].iloc[0]\n",
    "\n",
    "# data loading \n",
    "def load_data(df):\n",
    "    full_imgs = []\n",
    "    cropped_imgs = []\n",
    "    roi_imgs = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        full_img_path = match1(row['image file path'])\n",
    "        if full_img_path is None:\n",
    "            continue\n",
    "        cropped_img_path = match2(row['cropped image file path'])\n",
    "        if cropped_img_path is None:\n",
    "            continue\n",
    "        roi_img_path = match3(row['ROI mask file path'])\n",
    "        if roi_img_path is None:\n",
    "            continue\n",
    "        # roi_img_path = match4(row['ROI mask file path'])\n",
    "        # if roi_img_path is None:\n",
    "        #     continue\n",
    "\n",
    "        if full_img_path is not None and cropped_img_path is not None and roi_img_path is not None:\n",
    "            if os.path.exists(full_img_path) and os.path.exists(cropped_img_path) and os.path.exists(roi_img_path):\n",
    "                full_imgs.append(load_and_process_image(full_img_path))\n",
    "                cropped_imgs.append(load_and_process_image(cropped_img_path))\n",
    "                roi_imgs.append(load_and_process_image(roi_img_path))\n",
    "                labels.append(row['label'])\n",
    "            \n",
    "\n",
    "    return np.array(full_imgs), np.array(cropped_imgs), np.array(roi_imgs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, for calc_train - identify and remove duplicate image file paths.\n",
    "calc_train['image file path'].nunique()\n",
    "calc_train_model = calc_train.copy()\n",
    "calc_train_model = calc_train_model.drop_duplicates(subset=['image file path']).reset_index(drop=True)\n",
    "calc_train_model['image file path'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass_train.\n",
    "print(mass_train['image file path'].nunique())\n",
    "mass_train_model = mass_train.copy()\n",
    "mass_train_model = mass_train_model.drop_duplicates(subset=['image file path']).reset_index(drop=True)\n",
    "mass_train_model['image file path'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mass_test.\n",
    "print(mass_test['image file path'].nunique())\n",
    "mass_test_model = mass_test.copy()\n",
    "mass_test_model = mass_test_model.drop_duplicates(subset=['image file path']).reset_index(drop=True)\n",
    "mass_test_model['image file path'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_test.\n",
    "print(calc_test['image file path'].nunique())\n",
    "calc_test_model = calc_test.copy()\n",
    "calc_test_model = calc_test_model.drop_duplicates(subset=['image file path']).reset_index(drop=True)\n",
    "calc_test_model['image file path'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data-frame\n",
    "calc_train_model.info()\n",
    "print(\"/n\")\n",
    "mass_train_model.info()\n",
    "print(\"/n\")\n",
    "calc_test_model.info()\n",
    "print(\"/n\")\n",
    "mass_test_model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(match1(calc_train_model['image file path'][1000]))\n",
    "print(match2(calc_train_model['cropped image file path'][1000]))\n",
    "print(match3(calc_train_model['ROI mask file path'][1000]))\n",
    "calc_train_model['label'][1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_calc_full_train, x_calc_cropped_train, x_calc_roi_train, y_calc_train = [],[],[],[]\n",
    "x_calc_full_train, x_calc_cropped_train, x_calc_roi_train, y_calc_train = load_data(calc_train_model)\n",
    "\n",
    "x_calc_full_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_calc_full_test = x_calc_full_train[1000:]\n",
    "x_calc_cropped_test = x_calc_cropped_train[1000:]\n",
    "x_calc_roi_test = x_calc_roi_train[1000:]\n",
    "y_calc_test = y_calc_train[1000:]\n",
    "\n",
    "x_calc_full_train = x_calc_full_train[:1000]\n",
    "x_calc_cropped_train = x_calc_cropped_train[:1000]\n",
    "x_calc_roi_train = x_calc_roi_train[:1000]\n",
    "y_calc_train = y_calc_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_calc_roi_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mass_full_train, x_mass_cropped_train, x_mass_roi_train, y_mass_train = [],[],[],[]\n",
    "x_mass_full_train, x_mass_cropped_train, x_mass_roi_train, y_mass_train = load_data(mass_train_model)\n",
    "x_mass_cropped_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mass_full_test, x_mass_cropped_test, x_mass_roi_test, y_mass_test = [], [], [], []\n",
    "x_mass_full_test, x_mass_cropped_test, x_mass_roi_test, y_mass_test = load_data(mass_test_model)\n",
    "x_mass_cropped_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the training data \n",
    "x_full = np.concatenate([x_calc_full_train,x_mass_full_train], axis=0)\n",
    "x_cropped = np.concatenate([x_calc_cropped_train,x_mass_cropped_train], axis=0)\n",
    "x_roi = np.concatenate([x_calc_roi_train,x_mass_roi_train], axis=0)\n",
    "y = np.concatenate([y_calc_train,y_mass_train], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine testing data \n",
    "x_full_test = np.concatenate([x_calc_full_test,x_mass_full_test], axis=0)\n",
    "x_cropped_test = np.concatenate([x_calc_cropped_test,x_mass_cropped_test], axis=0)\n",
    "x_roi_test = np.concatenate([x_calc_roi_test,x_mass_roi_test], axis=0)\n",
    "y_test = np.concatenate([y_calc_test,y_mass_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape of np arrays above\n",
    "print(f\"x_full shape: {x_full.shape}, /n x_cropped shape: {x_cropped.shape}, /n x_roi shape: {x_roi.shape}, /n y shape: {y.shape}\")\n",
    "print(f\"x_full_test shape: {x_full_test.shape}, /n x_cropped_test shape: {x_cropped_test.shape}, /n x_roi_test shape: {x_roi_test.shape}, /n y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to categorical\n",
    "from tensoflow.keras.utils import to_categorical\n",
    "y = to_categorical(y, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multi_input_model(input_shape = (224, 224, 3)):\n",
    "    full_input = Input(shape=input_shape, name='full_input')\n",
    "    x1 = Conv2D(32, (3, 3), activation='relu', padding='same')(full_input)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "    x1 = Dropout(0.25)(x1)\n",
    "    \n",
    "    cropped_input = Input(shape=input_shape, name='cropped_input')\n",
    "    x2 = Conv2D(32, (3, 3), activation='relu', padding='same')(cropped_input)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "    x2 = Dropout(0.25)(x2)\n",
    "    \n",
    "    roi_input = Input(shape=input_shape, name='roi_input')\n",
    "    x3 = Conv2D(32, (3, 3), activation='relu', padding='same')(roi_input)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "    x3 = Dropout(0.25)(x3)\n",
    "    \n",
    "    merged = concatenate([x1, x2, x3])\n",
    "\n",
    "    # fully connected layers\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(merged)  # Add L2 regularization\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    output = Dense(3, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[full_input, cropped_input, roi_input], outputs=output)\n",
    "\n",
    "    # Compile model with Adam optimizer and custom learning rate\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of the model \n",
    "multi_input_model = build_multi_input_model()\n",
    "\n",
    "# learning rate scheduler that:\n",
    "# - Monitors the validation loss ('val_loss')\n",
    "# - Reduces learning rate by half (factor=0.5) \n",
    "# - Waits 3 epochs without improvement before reducing (patience=3)\n",
    "# - Won't reduce learning rate below 1e-6 (min_lr=1e-6)\n",
    "# - Prints messages when reducing learning rate (verbose=1)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# train model:\n",
    "history_1 = multi_input_model.fit(\n",
    "    # Input data: three different image representations\n",
    "    [x_full, x_cropped, x_roi],  # Training inputs\n",
    "    y,                           # Training labels/targets\n",
    "    \n",
    "    # Validation data in same format: ([inputs], targets)\n",
    "    validation_data=([x_full_test, x_cropped_test, x_roi_test], y_test),\n",
    "    \n",
    "    epochs=10,          # Number of complete passes through the training data\n",
    "    batch_size=16,      # Number of samples processed before model update\n",
    "    callbacks=[lr_scheduler]  # List of callbacks - only learning rate scheduler here\n",
    ")\n",
    "\n",
    "# print model summary \n",
    "multi_input_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check codes below for erros and bugs .....  save models ---- undf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second CNN Model: A different architecture to experiment\n",
    "\n",
    "def build_second_multi_input_model(input_shape=(224, 224, 1)):\n",
    "    \n",
    "    # Full input branch\n",
    "    full_input_2 = Input(shape=input_shape)\n",
    "    y1 = Conv2D(64, (3, 3), activation='relu', padding='same')(full_input_2)\n",
    "    y1 = BatchNormalization()(y1)\n",
    "    y1 = MaxPooling2D((2, 2))(y1)\n",
    "    y1 = Conv2D(128, (3, 3), activation='relu', padding='same')(y1)\n",
    "    y1 = BatchNormalization()(y1)\n",
    "    y1 = MaxPooling2D((2, 2))(y1)\n",
    "    y1 = Conv2D(256, (3, 3), activation='relu', padding='same')(y1)  # Increased filters for complexity\n",
    "    y1 = BatchNormalization()(y1)\n",
    "    y1 = MaxPooling2D((2, 2))(y1)\n",
    "    y1 = Flatten()(y1)\n",
    "\n",
    "    # Cropped input branch\n",
    "    cropped_input_2 = Input(shape=input_shape)\n",
    "    y2 = Conv2D(64, (3, 3), activation='relu', padding='same')(cropped_input_2)\n",
    "    y2 = BatchNormalization()(y2)\n",
    "    y2 = MaxPooling2D((2, 2))(y2)\n",
    "    y2 = Conv2D(128, (3, 3), activation='relu', padding='same')(y2)\n",
    "    y2 = BatchNormalization()(y2)\n",
    "    y2 = MaxPooling2D((2, 2))(y2)\n",
    "    y2 = Conv2D(256, (3, 3), activation='relu', padding='same')(y2)\n",
    "    y2 = BatchNormalization()(y2)\n",
    "    y2 = MaxPooling2D((2, 2))(y2)\n",
    "    y2 = Flatten()(y2)\n",
    "\n",
    "    # ROI input branch\n",
    "    roi_input_2 = Input(shape=input_shape)\n",
    "    y3 = Conv2D(64, (3, 3), activation='relu', padding='same')(roi_input_2)\n",
    "    y3 = BatchNormalization()(y3)\n",
    "    y3 = MaxPooling2D((2, 2))(y3)\n",
    "    y3 = Conv2D(128, (3, 3), activation='relu', padding='same')(y3)\n",
    "    y3 = BatchNormalization()(y3)\n",
    "    y3 = MaxPooling2D((2, 2))(y3)\n",
    "    y3 = Conv2D(256, (3, 3), activation='relu', padding='same')(y3)\n",
    "    y3 = BatchNormalization()(y3)\n",
    "    y3 = MaxPooling2D((2, 2))(y3)\n",
    "    y3 = Flatten()(y3)\n",
    "\n",
    "    # Concatenation and fully connected layers\n",
    "    combined_2 = concatenate([y1, y2, y3])\n",
    "    z = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(combined_2)  # Increased units and L2 regularization\n",
    "    z = Dropout(0.5)(z)\n",
    "    z = Dense(3, activation='softmax')(z)\n",
    "\n",
    "    # Compile model\n",
    "    second_model = Model(inputs=[full_input_2, cropped_input_2, roi_input_2], outputs=z)\n",
    "    second_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return second_model\n",
    "\n",
    "\n",
    "# Build the second model\n",
    "second_model = build_second_multi_input_model()\n",
    "\n",
    "# Summary of the second model\n",
    "second_model.summary()\n",
    "\n",
    "# Training the second model\n",
    "history_2 = second_model.fit([x_full, x_cropped, x_roi], y, epochs=20, batch_size=32, validation_data=([x_full_test, x_cropped_test, x_roi_test], y_test), callbacks=[ReduceLROnPlateau()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_third_multi_input_model(input_shape=(224, 224, 1), num_classes=3):\n",
    "    \n",
    "    # Full input branch\n",
    "    full_input_3 = Input(shape=input_shape)\n",
    "    x1 = Conv2D(32, (3, 3), activation='relu', padding='same')(full_input_3)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "    x1 = Conv2D(64, (3, 3), activation='relu', padding='same')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = MaxPooling2D((2, 2))(x1)\n",
    "    x1 = Flatten()(x1)\n",
    "\n",
    "    # Cropped input branch\n",
    "    cropped_input_3 = Input(shape=input_shape)\n",
    "    x2 = Conv2D(32, (3, 3), activation='relu', padding='same')(cropped_input_3)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = MaxPooling2D((2, 2))(x2)\n",
    "    x2 = Conv2D(64, (3, 3), activation='relu', padding='same')(x2)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = MaxPooling2D((2, 2))(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "\n",
    "    # ROI input branch\n",
    "    roi_input_3 = Input(shape=input_shape)\n",
    "    x3 = Conv2D(32, (3, 3), activation='relu', padding='same')(roi_input_3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = MaxPooling2D((2, 2))(x3)\n",
    "    x3 = Conv2D(64, (3, 3), activation='relu', padding='same')(x3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = MaxPooling2D((2, 2))(x3)\n",
    "    x3 = Flatten()(x3)\n",
    "\n",
    "    # Concatenation and fully connected layers\n",
    "    combined_3 = concatenate([x1, x2, x3])\n",
    "    z = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(combined_3)  # Reduced units\n",
    "    z = Dropout(0.5)(z)  # Dropout for regularization\n",
    "    output_3 = Dense(num_classes, activation='softmax')(z)  # Softmax for multi-class output\n",
    "\n",
    "    # Compile model\n",
    "    third_model = Model(inputs=[full_input_3, cropped_input_3, roi_input_3], outputs=output_3)\n",
    "    third_model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return third_model\n",
    "\n",
    "\n",
    "# Build the third model\n",
    "third_model = build_third_multi_input_model()\n",
    "\n",
    "# Summary of the third model\n",
    "third_model.summary()\n",
    "\n",
    "# Train the third model\n",
    "history_3 = third_model.fit(\n",
    "    [x_full, x_cropped, x_roi], \n",
    "    y, \n",
    "    epochs=20, \n",
    "    batch_size=32, \n",
    "    validation_data=([x_full_test, x_cropped_test, x_roi_test], y_test), \n",
    "    callbacks=[ReduceLROnPlateau()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Extraction for Each Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics for each model's history\n",
    "metrics_data = {\n",
    "    'Model': [],\n",
    "    'Epoch': [],\n",
    "    'Training Accuracy': [],\n",
    "    'Validation Accuracy': [],\n",
    "    'Training Loss': [],\n",
    "    'Validation Loss': []\n",
    "}\n",
    "\n",
    "# Assuming `history_1`, `history_2`, and `history_3` are the histories of the three models.\n",
    "# Add the metrics from the first model (replace with your actual history variable)\n",
    "for epoch in range(len(history_1.history['accuracy'])):\n",
    "    metrics_data['Model'].append('Model 1')\n",
    "    metrics_data['Epoch'].append(epoch + 1)\n",
    "    metrics_data['Training Accuracy'].append(history_1.history['accuracy'][epoch])\n",
    "    metrics_data['Validation Accuracy'].append(history_1.history['val_accuracy'][epoch])\n",
    "    metrics_data['Training Loss'].append(history_1.history['loss'][epoch])\n",
    "    metrics_data['Validation Loss'].append(history_1.history['val_loss'][epoch])\n",
    "\n",
    "# Repeat for the second model\n",
    "for epoch in range(len(history_2.history['accuracy'])):\n",
    "    metrics_data['Model'].append('Model 2')\n",
    "    metrics_data['Epoch'].append(epoch + 1)\n",
    "    metrics_data['Training Accuracy'].append(history_2.history['accuracy'][epoch])\n",
    "    metrics_data['Validation Accuracy'].append(history_2.history['val_accuracy'][epoch])\n",
    "    metrics_data['Training Loss'].append(history_2.history['loss'][epoch])\n",
    "    metrics_data['Validation Loss'].append(history_2.history['val_loss'][epoch])\n",
    "\n",
    "# Repeat for the third model\n",
    "for epoch in range(len(history_3.history['accuracy'])):\n",
    "    metrics_data['Model'].append('Model 3')\n",
    "    metrics_data['Epoch'].append(epoch + 1)\n",
    "    metrics_data['Training Accuracy'].append(history_3.history['accuracy'][epoch])\n",
    "    metrics_data['Validation Accuracy'].append(history_3.history['val_accuracy'][epoch])\n",
    "    metrics_data['Training Loss'].append(history_3.history['loss'][epoch])\n",
    "    metrics_data['Validation Loss'].append(history_3.history['val_loss'][epoch])\n",
    "\n",
    "# Create a DataFrame from the metrics data\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Display the metrics table\n",
    "print(metrics_df)\n",
    "\n",
    "# Optional: Save the metrics table to a CSV file\n",
    "metrics_df.to_csv('model_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed packages for visualization.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a dictionary to hold the accuracy and loss data\n",
    "histories = {\n",
    "    'Model 1': history_1.history,\n",
    "    'Model 2': history_2.history,\n",
    "    'Model 3': history_3.history\n",
    "}\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(2, 2, 1)\n",
    "for model, history in histories.items():\n",
    "    epochs = range(1, len(history['accuracy']) + 1)  # Get the correct range of epochs\n",
    "    plt.plot(epochs, history['accuracy'], label=f'{model} - Train')\n",
    "    plt.plot(epochs, history['val_accuracy'], linestyle='--', label=f'{model} - Val')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(2, 2, 2)\n",
    "for model, history in histories.items():\n",
    "    epochs = range(1, len(history['loss']) + 1)  # Get the correct range of epochs\n",
    "    plt.plot(epochs, history['loss'], label=f'{model} - Train')\n",
    "    plt.plot(epochs, history['val_loss'], linestyle='--', label=f'{model} - Val')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
