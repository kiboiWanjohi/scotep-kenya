{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiboiWanjohi/scotep-kenya/blob/main/histopathology/histopathology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlYChzqeQYvR"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjl2zG6FQ_fP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6poSqZtRSKt"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pfPRCh-RVAr"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/Stat_Docs/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZh8SgUWRZli"
      },
      "outputs": [],
      "source": [
        "# Change permission\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV878TBMQcmE"
      },
      "source": [
        "### Download Histopathology Dataset\n",
        "\n",
        "Link To Breast Histopathology Dataset [Here](https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK-4q3o8QhiJ"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d paultimothymooney/breast-histopathology-images\"\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-CMKbPg0XTS"
      },
      "outputs": [],
      "source": [
        "# unzip content\n",
        "! unzip /content/breast-histopathology-images.zip -d /content/breast-histopathology-images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpKXSs8v0XTT"
      },
      "outputs": [],
      "source": [
        "# check disk usage\n",
        "! df -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbNwk8KG0XTU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "import seaborn as sns\n",
        "import random\n",
        "import warnings\n",
        "import PIL\n",
        "import random\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgo86s300XTU"
      },
      "outputs": [],
      "source": [
        "image_dir = 'content/jpeg'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "breast_imgs = glob.glob('/content/breast-histopathology-images/IDC_regular_ps50_idx5/**/*.png', recursive = True)\n",
        "for imgname in breast_imgs[:5]:\n",
        "    print(imgname)\n"
      ],
      "metadata": {
        "id": "xU97tD8TJSGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_cancer_imgs = []\n",
        "cancer_imgs = []\n",
        "\n",
        "for img in breast_imgs:\n",
        "    if img[-5] == '0' :\n",
        "        non_cancer_imgs.append(img)\n",
        "\n",
        "    elif img[-5] == '1' :\n",
        "        cancer_imgs.append(img)\n",
        "non_cancer_num = len(non_cancer_imgs)  # No cancer\n",
        "cancer_num = len(cancer_imgs)   # Cancer\n",
        "\n",
        "total_img_num = non_cancer_num + cancer_num\n",
        "\n",
        "print('Number of Images of no cancer: {}' .format(non_cancer_num))   # images of Non cancer\n",
        "print('Number of Images of cancer : {}' .format(cancer_num))   # images of cancer\n",
        "print('Total Number of Images : {}' .format(total_img_num))\n",
        ""
      ],
      "metadata": {
        "id": "Rp8OCEZkJWeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Data_cleaning_1.left_or_right_breast.value_counts().RIGHT\n",
        "y = Data_cleaning_1.left_or_right_breast.value_counts().LEFT\n",
        "\n",
        "print(x, y)\n",
        ""
      ],
      "metadata": {
        "id": "PkM6AaTaJf0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15, 15))\n",
        "\n",
        "some_non = np.random.randint(0, len(non_cancer_imgs), 18)\n",
        "some_can = np.random.randint(0, len(cancer_imgs), 18)\n",
        "\n",
        "s = 0\n",
        "for num in some_non:\n",
        "\n",
        "        img = image.load_img((non_cancer_imgs[num]), target_size=(100, 100))\n",
        "        img = image.img_to_array(img)\n",
        "\n",
        "        plt.subplot(6, 6, 2*s+1)\n",
        "        plt.axis('off')\n",
        "        plt.title('no cancer')\n",
        "        plt.imshow(img.astype('uint8'))\n",
        "        s += 1\n",
        "\n",
        "s = 1\n",
        "for num in some_can:\n",
        "        img = image.load_img((non_cancer_imgs[num]), target_size=(100, 100))\n",
        "        img = image.img_to_array(img)\n",
        "\n",
        "        plt.subplot(6, 6, 2*s)\n",
        "        plt.axis('off')\n",
        "        plt.title('cancer')\n",
        "        plt.imshow(img.astype('uint8'))\n",
        "        s += 1\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "zt2V638iJlgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Modeling\n",
        "# Randomly sample images from two lists, 'non_cancer_imgs' and 'cancer_imgs'\n",
        "some_non_img = random.sample(non_cancer_imgs, len(non_cancer_imgs))\n",
        "some_can_img = random.sample(cancer_imgs, len(cancer_imgs))\n",
        "\n",
        "# Initialize empty arrays to store image data and labels\n",
        "non_img_arr = []  # Array for non-cancer images\n",
        "can_img_arr = []  # Array for cancer images\n",
        "\n",
        "# Loop through each image in the 'some_non_img' list\n",
        "for img in some_non_img:\n",
        "    # Read the image in color mode\n",
        "    n_img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
        "    if n_img is not None:\n",
        "        n_img_size = cv2.resize(n_img, (50, 50), interpolation=cv2.INTER_LINEAR)  # Resize the image\n",
        "        non_img_arr.append((n_img_size, 0))  # Append image and label as a tuple\n",
        "\n",
        "# Loop through each image in the 'some_can_img' list\n",
        "for img in some_can_img:\n",
        "    # Read the image in color mode\n",
        "    c_img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
        "    if c_img is not None:\n",
        "        c_img_size = cv2.resize(c_img, (50, 50), interpolation=cv2.INTER_LINEAR)  # Resize the image\n",
        "        can_img_arr.append((c_img_size, 1))  # Append image and label as a tuple\n",
        "\n",
        "X = []  # List for image data\n",
        "y = []  # List for labels\n",
        "\n",
        "# Separate the images and labels\n",
        "breast_img_arr = non_img_arr + can_img_arr  # Combine the lists\n",
        "random.shuffle(breast_img_arr)  # Shuffle the combined list\n",
        "# Split into features (X) and labels (y)\n",
        "X = [feature for feature, label in breast_img_arr]\n",
        "y = [label for feature, label in breast_img_arr]\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Print the shape of the 'X' array\n",
        "print('X shape: {}'.format(X.shape))\n",
        "print('y shape: {}'.format(y.shape))"
      ],
      "metadata": {
        "id": "eY6GR_9pJtKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets, with a test size of 20%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "# Define a rate (percentage) for subsampling the training data\n",
        "rate = 0.5\n",
        "\n",
        "# Calculate the number of samples to keep in the training data based on the rate\n",
        "num = int(X.shape[0] * rate)\n",
        "\n",
        "# Convert the categorical labels in 'y_train' and 'y_test' to one-hot encoded format\n",
        "y_train = to_categorical(y_train, 2)  # Assuming there are 2 classes (non-cancer and cancer)\n",
        "y_test = to_categorical(y_test, 2)\n",
        "\n",
        "\n",
        "print('X_train shape : {}' .format(X_train.shape))\n",
        "print('X_test shape : {}' .format(X_test.shape))\n",
        "print('y_train shape : {}' .format(y_train.shape))\n",
        "print('y_test shape : {}' .format(y_test.shape))\n"
      ],
      "metadata": {
        "id": "bR2s1T79JuYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Create data generators for training and testing\n",
        "train_datagen = datagen.flow(X_train, y_train, batch_size=32)\n",
        "test_datagen = datagen.flow(X_test, y_test, batch_size=32, shuffle=False)\n",
        "# Define an EarlyStopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',          # Monitor the validation loss\n",
        "    patience=5,                  # Number of epochs with no improvement after which training will be stopped\n",
        "    min_delta=1e-7,              # Minimum change in the monitored quantity to be considered an improvement\n",
        "    restore_best_weights=True,   # Restore model weights from the epoch with the best value of monitored quantity\n",
        ")\n",
        "\n",
        "# Define a ReduceLROnPlateau callback\n",
        "plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',   # Monitor the validation loss\n",
        "    factor=0.2,           # Factor by which the learning rate will be reduced (new_lr = lr * factor)\n",
        "    patience=2,           # Number of epochs with no improvement after which learning rate will be reduced\n",
        "    min_delta=1e-7,  # Minimum change in the monitored quantity to trigger a learning rate reduction\n",
        "    cooldown=0,           # Number of epochs to wait before resuming normal operation after learning rate reduction\n",
        "    verbose=1             # Verbosity mode (1: update messages, 0: no messages)\n",
        ")\n",
        "# Set a random seed for reproducibility\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "dB3URueeJ1nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Sequential model\n",
        "model = tf.keras.Sequential([\n",
        "    # Convolutional layer with 32 filters, a 3x3 kernel, 'same' padding, and ReLU activation\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(50, 50, 3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # MaxPooling layer with a 2x2 pool size and default stride (2)\n",
        "    tf.keras.layers.MaxPooling2D(strides=2),\n",
        "\n",
        "    # Convolutional layer with 64 filters, a 3x3 kernel, 'same' padding, and ReLU activation\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # MaxPooling layer with a 3x3 pool size and stride of 2\n",
        "    tf.keras.layers.MaxPooling2D((3, 3), strides=2),\n",
        "\n",
        "    # Convolutional layer with 128 filters, a 3x3 kernel, 'same' padding, and ReLU activation\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # MaxPooling layer with a 3x3 pool size and stride of 2\n",
        "    tf.keras.layers.MaxPooling2D((3, 3), strides=2),\n",
        "\n",
        "    # Convolutional layer with 128 filters, a 3x3 kernel, 'same' padding, and ReLU activation\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    # MaxPooling layer with a 3x3 pool size and stride of 2\n",
        "    tf.keras.layers.MaxPooling2D((3, 3), strides=2),\n",
        "\n",
        "    # Flatten the output to prepare for fully connected layers\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fully connected layer with 128 units and ReLU activation\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    # Output layer with 2 units (binary classification) and softmax activation\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "9TLiulnIJ6BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a summary of the model architecture\n",
        "model.summary()\n",
        ""
      ],
      "metadata": {
        "id": "pkD2TADbJ9Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with Adam optimizer, binary cross-entropy loss, and accuracy metric\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XtNXHlKGJ_kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    validation_data = (X_test, y_test),\n",
        "                    epochs = 25,\n",
        "                    batch_size = 75,\n",
        "                    callbacks=[early_stopping, plateau])"
      ],
      "metadata": {
        "id": "uxNCRkTgKCKX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}