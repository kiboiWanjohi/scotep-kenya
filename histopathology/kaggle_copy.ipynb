{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copied from Basel Anaya - Cesar Pereiro Garcia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-requisites and Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /content/drive/MyDrive/Stat_Docs/kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change permission\n",
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Download \n",
    "\n",
    "Link to dataset -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle datasets download paultimothymooney/breast-histopathology-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# unzip content\n",
    "! unzip /content/breast-histopathology-images.zip -d /content/breast-histopathology-images    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check disk usage\n",
    "! df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install plotly \n",
    "! pip install seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as patches\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "from matplotlib.image import imread\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import glob\n",
    "import PIL\n",
    "import random\n",
    "\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '' #rename path as seen in colab \n",
    "breast_imgs=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):\n",
    "            breast_imgs.append(os.path.join(root, file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists for information\n",
    "patient_numbers = []\n",
    "cancer_status = []\n",
    "x_coords = []\n",
    "y_coords = []\n",
    "file_names = []\n",
    "file_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in breast_imgs:\n",
    "    parts = img.split('/') # /content/breast-histopathology-images/10264/1/10264_idx5_x1601_y1451_class1.png becomes: parts = ['content', 'breast-histopathology-images', '10264', '1', '10264_idx5_x1601_y1451_class1.png']\n",
    "    filename = parts[-1] #last component of the split path, which is the filename\n",
    "    patient_number = parts[-3] #hird-to-last component of the path, which corresponds to the patient number.\n",
    "    info = filename.rstrip('.png').split('_') #Removes the .png extension from the filename using .rstrip('.png').Splits the remaining part of the filename into components using '_' as the delimiter.Example: ['10264', 'idx5', 'x1601', 'y1451', 'class1'].\n",
    "    x_coord = int(info[2][1:]) #Extracts the third element ('x1601'), removes the leading 'x' using slicing ([1:]), and converts it to an integer.\n",
    "    y_coord = int(info[3][1:]) #Extracts the fourth element ('y1451'), removes the leading 'y' using slicing ([1:]), and converts it to an integer.\n",
    "    status = int(info[4][-1]) #Extracts the last element ('class1'), gets the last character ([-1]), and converts it to an integer.\n",
    "    patient_numbers.append(patient_number) \n",
    "    cancer_status.append(status)\n",
    "    x_coords.append(x_coord)\n",
    "    y_coords.append(y_coord)\n",
    "    file_names.append(filename)\n",
    "    file_paths.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Patient_Number': patient_numbers,\n",
    "    'Cancer_Status': cancer_status,\n",
    "    'X_Coord': x_coords,\n",
    "    'Y_Coord': y_coords,\n",
    "    'File_Name': file_names,\n",
    "    'File_Path': file_paths\n",
    "})\n",
    "\n",
    "df.sort_values(by=['Patient_Number', 'X_Coord', 'Y_Coord'], inplace=True)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = df['Patient Number'].unique()\n",
    "fig, axs = plt.subplots(5,3, figsize = 20,27)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(3):\n",
    "        if 3 * i + j < len(patient_ids):\n",
    "            patient_id = patient_ids[3 * i + j]\n",
    "            patient_df = df[df[\"Patient_Number\"] == patient_id]\n",
    "            axs[i,j].scatter(patient_df[patient_df['Cancer_Status'] == 0]['X_Coord'], patient_df[patient_df['Cancer_Status'] == 0]['Y_Coord'], c = 'blue', label='No Cancer', s = 20)\n",
    "            axs[i,j].scatter(patient_df[patient_df['Cancer_Status'] == 1]['X_Coord'], patient_df[patient_df['Cancer_Status'] == 1]['Y_Coord'], c = 'blue', label='No Cancer', s = 20)\n",
    "            axs[i,j].set_title('Patient' + str(patient_id))\n",
    "            axs[i,j].set_xlabel('X Coord')\n",
    "            axs[i,j].set_ylabel(\"Y Coord\")\n",
    "            axs[i,j].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check image dataframe \n",
    "for imgname in breast_imgs[:7]:\n",
    "    print(imgname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Full_Path'] = df['File_path']\n",
    "\n",
    "# load images and coordincates \n",
    "def load_image_and_coords_from_path(file_path, label, x_coord, y_coord):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_png(image, channels = 3) #decode to an RGB image\n",
    "    image = tf.image.resize(image, [50,50])\n",
    "    return (image, tf.cast(label, tf.float32), tf.cast(x_coord, tf.float32),tf.cast(y_coord, tf.float32)) #returns a tuple - processed image, label to 32-bit floating point \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df):\n",
    "    path_ds = tf.Dataset.from_tensor_slices((\n",
    "        df['Full_Path'].values,\n",
    "        df['Cancer_Status'].values,\n",
    "        df['X_Coord'].values,\n",
    "        df['Y_Coord'].values\n",
    "    ))\n",
    "    dataset = path_ds.map(load_image_and_coords_from_path)\n",
    "    return dataset.batch(512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack features and labels\n",
    "def unpack_features_labels(image, label, x_coord, y_coord):\n",
    "    return (image, tf.stack([x_coord, y_coord], axis=1)), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe into train....\n",
    "train_df, temp_df = train_test_split(df, test_size=0.15, random_state=42, stratify=df['Patient_Number'])\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.15, random_state=42, stratify=df['Patient_Number'])\n",
    "\n",
    "train_dataset = create_dataset(train_df)\n",
    "train_dataset = train_dataset.map(unpack_features_labels)\n",
    "\n",
    "valid_dataset = create_dataset(valid_df)\n",
    "val_dataset = valid_dataset.map(unpack_features_labels)\n",
    "\n",
    "test_dataset = create_dataset(test_df)\n",
    "test_dataset = test_dataset.map(unpack_features_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify order from first batch \n",
    "for (images, coords), labels in train_dataset.take(1):\n",
    "    x_coords, y_coords = tf.unstack(coords, axis = 1)\n",
    "    for i in range(tf.shape(labels)[0]):\n",
    "        print(f'Image {i}: Label\" {labels[i].numpy()}, X_Coord: {x_coords[i].numpy()}, Y_Coord: {y_coords[i].numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image function\n",
    "def load_image(file_path):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_png(image, channels =3)\n",
    "    image - tf.image.resize(image, [50, 50])\n",
    "    return image.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get images with coords -- DataFrame and a center index as parameters. This function will get surrounding images around a central point.\n",
    "def get_surrounding_images_with_coords(df, center_idx):\n",
    "    center_x = df.iloc[center_idx]['X_Coord']\n",
    "    center_y = df.iloc[center_idx]['Y_Coord']\n",
    "    # Creates a list of coordinate pairs for a 4x4 grid centered around the central point. Each grid cell is 50x50 pixels\n",
    "    patch_coords = [(x,y) for y in range(center_y - 1 * 50, center_y + 3 * 50,  50) for x in range(center_x - 1 * 50, center_x + 3 * 50, 50)]\n",
    "    # an empty 200x200 (4x50 by 4x50) RGB image array to store the final composite image.\n",
    "    image_patch = np.zeros((4 * 50, 4 * 50, 3), dtype=np.uint8)\n",
    "    # empty list to store coordinates, labels, and whether images are original or mirrored.\n",
    "    used_coords_labels = []\n",
    "    # Iterates through the coordinate pairs, calculating the row and column position in the 4x4 grid\n",
    "    for i, (x, y) in enumerate(patch_coords):\n",
    "        row = i // 4\n",
    "        col = i % 4\n",
    "        image_df = df[(df['X_Coord'] == x) & (df['Y_Coord'] == y)]\n",
    "        # If no image exists at these coordinates:Finds the nearest image using Manhattan distanceLoads that image\n",
    "        if image_df.empty:\n",
    "            nearest_idx = ((df['X_Coord'] - x).abs() + (df['Y_Coord'] - y).abs()).argmin()\n",
    "            nearest_image_df = df.iloc[nearest_idx]\n",
    "            image = load_image(nearest_image_df['Full_Path'])\n",
    "            # Flips the image horizontally or vertically based on its position relative to the center.\n",
    "            if nearest_image_df['X_Coord'] < center_x:\n",
    "                image = np.fliplr(image)\n",
    "            elif nearest_image_df['X_Coord'] > center_x:\n",
    "                image = np.flipud(image)\n",
    "            # Records that this position used a mirrored image.\n",
    "            used_coords_labels.append((nearest_image_df['X_Coord'], nearest_image_df['Y_Coord'], nearest_image_df['Cancer_Status'], 'Espejo'))\n",
    "        else:\n",
    "            image = load_image(image_df.iloc[0]['Full_Path'])\n",
    "            used_coords_labels.append((x, y, image_df.iloc[0]['Cancer_Status'], 'Original'))\n",
    "        \n",
    "        # If an image exists at these coordinates, loads it and marks it as original.\n",
    "        image_patch[row * 50:(row + 1) * 50, col * 50:(col + 1) * 50, :] = image\n",
    "    \n",
    "    # Places the loaded image in the correct position in the composite image.\n",
    "    green_mask = np.full((50, 50, 3), [0, 255, 0], dtype=np.uint8)\n",
    "    image_patch[100:150, 100:150, :] = np.clip(image_patch[100:150, 100:150, :] + green_mask * 0.2, 0, 255)\n",
    "\n",
    "    # Adds a semi-transparent green overlay to the center image in the grid.\n",
    "    return image_patch, used_coords_labels\n",
    "\n",
    "# Returns the composite image and the list of coordinates/labels used.\n",
    "# Calls the function with index 55 as the center image\n",
    "center_image_idx = 55\n",
    "patch_image, patch_coords_labels = get_surrounding_images_with_coords(df, center_image_idx)\n",
    "\n",
    "# Prints the coordinates and labels of all images used, then displays the composite image.\n",
    "print(\"Coordinates and labels of the images in the patch:\")\n",
    "for coord_label in patch_coords_labels:\n",
    "    print(coord_label)\n",
    "\n",
    "\n",
    "plt.imshow(patch_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU and GPU set-up --  colab ()()\n",
    "USO_TPU = bool(1)\n",
    "USO_GPU = bool(0)\n",
    "\n",
    "\n",
    "\n",
    "if USO_TPU:\n",
    "    \n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n",
    "    \n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    \n",
    "\n",
    "if USO_GPU: \n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model build up\n",
    "import keras\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Flatten, Dropout, Concatenate, BatchNormalization, Add, Resizing, Cropping2D, RandomRotation, RandomBrightness, RandomFlip\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ConvNeXtTiny, NASNetMobile, VGG16, EfficientNetV2M, EfficientNetB3\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.layers import Input, RandomFlip, RandomRotation, RandomBrightness, GaussianNoise\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment code if strategy doesn't work\n",
    "with strategy.scope():\n",
    "    # input for images 50x50 pixels and 3 channels - RGB\n",
    "    image_input = Input(shape=(50, 50, 3), name='image_input')\n",
    "    # input layer for coordinates \n",
    "    coords_input = Input(shape=(2,), name='coords_input')\n",
    "    # data augmentation (add image brightness, flip add random noise)\n",
    "    x = RandomBrightness(0.2)(image_input)\n",
    "    x = RandomFlip()(x)\n",
    "    x = GaussianNoise(0.2)(x)\n",
    "    # preprocess specific to EfficientNetV2M\n",
    "    processed = preprocess_input(x)\n",
    "    # load base EfficientNetB3 model\n",
    "    base_model = EfficientNetB3(include_top = False, weights = 'imagenet', input_tensor=processed)\n",
    "    # freeze layers of the base model and set as trainable\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "    # flatten output of base model\n",
    "    flattened_base_model = Flatten()(base_model.output)\n",
    "    # dense layers \n",
    "    dense1 = Dense(128, activation='relu')(flattened_base_model)\n",
    "    batch_norm1 = BatchNormalization()(dense1)\n",
    "    dropout1 = Dropout(0.1)(batch_norm1)  \n",
    "\n",
    "    dense2 = Dense(64, activation='relu')(dropout1)\n",
    "    batch_norm2 = BatchNormalization()(dense2)\n",
    "    dropout2 = Dropout(0.2)(batch_norm2)  \n",
    "\n",
    "    dense3 = Dense(32, activation='relu')(dropout2)\n",
    "    batch_norm3 = BatchNormalization()(dense3)\n",
    "\n",
    "    # output layer\n",
    "    output = Dense(1, activation='sigmoid')(batch_norm3)\n",
    "\n",
    "    model = Model(input=[image_input, coords_input], outputs=output)\n",
    "\n",
    "    model.compile(optimizer = Adam(learning_rate=0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping \n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce learning rate\n",
    "plateau = ReduceLROnPlateau(monitor='val_loss', factor = 0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom learning rate scheduler\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class LRScheduler(Callback):\n",
    "    def __init__(self, schedule):\n",
    "        super(LRScheduler, self).__init__()\n",
    "        self.schedule = schedule\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, \"lr\"):\n",
    "            raise ValueError(\"Optimizer must hae a \"lr\" attribute.\")\n",
    "        # get current learning rate from model\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "        # call schedule function to get scheduled learning rate \n",
    "        scheduled_lr = self.schedule(epoch, lr)\n",
    "        # set value back to optimizer befor epoch starts \n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "        print(f\"Epoch {epoch+1}: Learning rate is {scheduled_lr}\")\n",
    "    \n",
    "    # custom scheduler function\n",
    "    def lr_scheduler(epoch, lr):\n",
    "        if epoch < 20:\n",
    "            return lr\n",
    "        else:\n",
    "            return lr * tf.math.exp(-0.1)\n",
    "\n",
    "    # instantiate LRScheduler with function\n",
    "    lr_scheduler_callback = LRScheduler(lr_scheduler)\n",
    "\n",
    "    # define class weights if classes are imbalances\n",
    "    class_weights - {0: 1.0, 1: 5.0} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=100,  # cheza hapa \n",
    "    verbose=1,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping, plateau, lr_scheduler_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "loss = history.history['loss']\n",
    "val = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val, label='Validation Loss')\n",
    "plt.title('Training Loss Curves')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
